# hyperparameters
batch_size = 32  # how many independent sequences will we process in parallel?
block_size = 128  # maximum context length for predictions
max_iters = 10000
eval_interval = 100
learning_rate = 1e-3
device = 'cuda' if torch.cuda.is_available() else 'cpu'
eval_iters = 200
n_embd = 128
n_head = 8
n_layer = 8
dropout = 0.2